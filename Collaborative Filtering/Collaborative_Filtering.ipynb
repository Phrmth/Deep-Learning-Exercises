{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Collaborative Filtering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpJn5bj+XlizHegUzB0G6T"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_BmRKpvNGHd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDzAO7w5OxnE",
        "outputId": "a8c33292-aba1-496d-9fdb-a3fd1e62722d"
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-01 18:08:54--  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-07-01 18:08:54 (6.59 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guutYsfOQsP-",
        "outputId": "4d38d2f0-e879-44ae-d358-9bb814e92d83"
      },
      "source": [
        "!unzip ml-latest-small.zip -d movielens"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ml-latest-small.zip\n",
            "   creating: movielens/ml-latest-small/\n",
            "  inflating: movielens/ml-latest-small/links.csv  \n",
            "  inflating: movielens/ml-latest-small/tags.csv  \n",
            "  inflating: movielens/ml-latest-small/ratings.csv  \n",
            "  inflating: movielens/ml-latest-small/README.txt  \n",
            "  inflating: movielens/ml-latest-small/movies.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN5GZeYRQ-YP"
      },
      "source": [
        "movies = pd.read_csv(\"./movielens/ml-latest-small/movies.csv\")\n",
        "ratings = pd.read_csv(\"./movielens/ml-latest-small/ratings.csv\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyi8ZtgXRGsn"
      },
      "source": [
        "user_ids = ratings[\"userId\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "movie_ids = ratings[\"movieId\"].unique().tolist()\n",
        "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
        "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
        "ratings[\"user\"] = ratings[\"userId\"].map(user2user_encoded)\n",
        "ratings[\"movie\"] = ratings[\"movieId\"].map(movie2movie_encoded)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvDDZTOtRXN9",
        "outputId": "dd0e4e8e-88d9-47f8-fb62-437c0b85a8d5"
      },
      "source": [
        "num_users = len(user2user_encoded)\n",
        "num_movies = len(movie_encoded2movie)\n",
        "ratings[\"rating\"] = ratings[\"rating\"].values.astype(np.float32)\n",
        "# min and max ratings will be used to normalize the ratings later\n",
        "min_rating = min(ratings[\"rating\"])\n",
        "max_rating = max(ratings[\"rating\"])\n",
        "\n",
        "print(\n",
        "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
        "        num_users, num_movies, min_rating, max_rating\n",
        "    )\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKNxr_ZoRVx3"
      },
      "source": [
        "ratings = ratings.sample(frac=1, random_state=42)\n",
        "x = ratings[[\"user\", \"movie\"]].values\n",
        "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
        "y = ratings[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "# Assuming training on 90% of the data and validating on 10%.\n",
        "train_indices = int(0.9 * ratings.shape[0])\n",
        "x_train, x_val, y_train, y_val = (\n",
        "    x[:train_indices],\n",
        "    x[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2amfCIFRHH0"
      },
      "source": [
        "EMBEDDING_SIZE = 3\n",
        "\n",
        "\n",
        "class RecommenderNet(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(RecommenderNet, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "        # Add all the components (including bias)\n",
        "        x = dot_user_movie + user_bias + movie_bias\n",
        "        # The sigmoid activation forces the rating to between 0 and 1\n",
        "        return tf.nn.sigmoid(x)\n",
        "\n",
        "\n",
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXrWhp8vSUN5",
        "outputId": "80a5998d-bee3-437a-d461-0259fe3189fa"
      },
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1418/1418 [==============================] - 8s 3ms/step - loss: 0.6406 - val_loss: 0.6196\n",
            "Epoch 2/5\n",
            "1418/1418 [==============================] - 4s 3ms/step - loss: 0.6107 - val_loss: 0.6115\n",
            "Epoch 3/5\n",
            "1418/1418 [==============================] - 4s 3ms/step - loss: 0.6035 - val_loss: 0.6079\n",
            "Epoch 4/5\n",
            "1418/1418 [==============================] - 4s 3ms/step - loss: 0.5995 - val_loss: 0.6058\n",
            "Epoch 5/5\n",
            "1418/1418 [==============================] - 4s 3ms/step - loss: 0.5965 - val_loss: 0.6043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VEXawFOSjNT"
      },
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cRyJnmGSoi9",
        "outputId": "ca71ff63-094e-4ce2-9c5c-9880918409d2"
      },
      "source": [
        "movie_df = pd.read_csv(\"./movielens/ml-latest-small/movies.csv\")\n",
        "\n",
        "# Let us get a user and see the top recommendations.\n",
        "user_id = ratings.userId.sample(1).iloc[0]\n",
        "movies_watched_by_user = ratings[ratings.userId == user_id]\n",
        "movies_not_watched = movie_df[\n",
        "    ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
        "][\"movieId\"]\n",
        "movies_not_watched = list(\n",
        "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
        ")\n",
        "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
        "user_encoder = user2user_encoded.get(user_id)\n",
        "user_movie_array = np.hstack(\n",
        "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
        ")\n",
        "ratings = model.predict(user_movie_array).flatten()\n",
        "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "recommended_movie_ids = [\n",
        "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
        "]\n",
        "\n",
        "print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "print(\"====\" * 9)\n",
        "print(\"Movies with high ratings from user\")\n",
        "print(\"----\" * 8)\n",
        "top_movies_user = (\n",
        "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
        "    .head(5)\n",
        "    .movieId.values\n",
        ")\n",
        "movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "for row in movie_df_rows.itertuples():\n",
        "    print(row.title, \":\", row.genres)\n",
        "\n",
        "print(\"----\" * 8)\n",
        "print(\"Top 10 movie recommendations\")\n",
        "print(\"----\" * 8)\n",
        "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "for row in recommended_movies.itertuples():\n",
        "    print(row.title, \":\", row.genres)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Showing recommendations for user: 20\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Wallace & Gromit: The Best of Aardman Animation (1996) : Adventure|Animation|Comedy\n",
            "West Side Story (1961) : Drama|Musical|Romance\n",
            "Muppets From Space (1999) : Children|Comedy\n",
            "Bridget Jones's Diary (2001) : Comedy|Drama|Romance\n",
            "Lord of the Rings: The Fellowship of the Ring, The (2001) : Adventure|Fantasy\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Shawshank Redemption, The (1994) : Crime|Drama\n",
            "One Flew Over the Cuckoo's Nest (1975) : Drama\n",
            "Star Wars: Episode V - The Empire Strikes Back (1980) : Action|Adventure|Sci-Fi\n",
            "Princess Bride, The (1987) : Action|Adventure|Comedy|Fantasy|Romance\n",
            "Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981) : Action|Adventure\n",
            "Apocalypse Now (1979) : Action|Drama|War\n",
            "Goodfellas (1990) : Crime|Drama\n",
            "Godfather: Part II, The (1974) : Crime|Drama\n",
            "Cool Hand Luke (1967) : Drama\n",
            "Fight Club (1999) : Action|Crime|Drama|Thriller\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
